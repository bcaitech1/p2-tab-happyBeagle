{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python2",
   "display_name": "Python 2",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import image_generate\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "training dataset: 0it [00:00, ?it/s][Info] get_final_data........\n",
      "training dataset: 12it [00:09,  1.24it/s]\n",
      "validation dataset: 0it [00:00, ?it/s][Info] get_final_data........\n",
      "validation dataset: 12it [00:10,  1.09it/s]\n",
      "test dataset: 0it [00:00, ?it/s][Info] get_final_data........\n",
      "test dataset: 12it [00:09,  1.27it/s]\n",
      "training dataset:   0%|          | 0/5914 [00:00<?, ?it/s][Info] generate_pixel........\n",
      "training dataset: 100%|██████████| 5914/5914 [35:57<00:00,  2.74it/s]\n",
      "validation dataset:   0%|          | 0/5914 [00:00<?, ?it/s][Info] generate_pixel........\n",
      "validation dataset: 100%|██████████| 5914/5914 [35:45<00:00,  2.76it/s]\n",
      "test dataset:   0%|          | 0/5914 [00:00<?, ?it/s][Info] generate_pixel........\n",
      "test dataset: 100%|██████████| 5914/5914 [35:39<00:00,  2.76it/s]\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv(\"/content/drive/MyDrive/boostcamp/stage2_tabular/my_src_1/input/train.csv\", parse_dates=[\"order_date\"])\n",
    "train_data[\"year_month\"] = train_data[\"order_date\"].dt.strftime('%Y-%m')\n",
    "\n",
    "train_year = {\"start\": \"2009-12\", \"end\": \"2010-12\"}\n",
    "valid_year = {\"start\": \"2010-11\", \"end\": \"2011-11\"}\n",
    "test_year = {\"start\": \"2010-12\", \"end\": \"2011-12\"}\n",
    "\n",
    "train, train_y, valid, valid_y, test, test_y = image_generate.generate_image(train_data, train_year, valid_year, test_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv(\"/content/drive/MyDrive/boostcamp/stage2_tabular/my_src/data/train_img.csv\")\n",
    "train_y.to_csv(\"/content/drive/MyDrive/boostcamp/stage2_tabular/my_src/data/train_label.csv\")\n",
    "\n",
    "valid.to_csv(\"/content/drive/MyDrive/boostcamp/stage2_tabular/my_src/data/valid_img.csv\")\n",
    "valid_y.to_csv(\"/content/drive/MyDrive/boostcamp/stage2_tabular/my_src/data/valid_label.csv\")\n",
    "\n",
    "test.to_csv(\"/content/drive/MyDrive/boostcamp/stage2_tabular/my_src/data/test_img.csv\")\n",
    "test_y.to_csv(\"/content/drive/MyDrive/boostcamp/stage2_tabular/my_src/data/test_label.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, data, label):\n",
    "        super().__init__()\n",
    "        self.image_list = data.drop(\"id\", axis=1).to_numpy().reshape(-1, 28, 28)\n",
    "        self.label_list = label.to_numpy()\n",
    "        self.transform =transforms.Compose(\n",
    "                                            [transforms.ToTensor()]\n",
    "                                            )\n",
    "    def __len__(self):\n",
    "        return len(self.label_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        label = self.label_list[idx]\n",
    "        img_arr = self.image_list[idx]\n",
    "\n",
    "        img = Image.fromarray(img_arr)\n",
    "        img = self.transform(img)\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    " train_dataset = ImageDataset(train, train_y[\"label\"])\n",
    " valid_dataset = ImageDataset(valid, valid_y[\"label\"])\n",
    " test_dataset = ImageDataset(test, test_y[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:132: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:143.)\n  img = torch.from_numpy(np.array(pic, np.float32, copy=False))\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "img_0, label_0 = train_dataset[0]\n",
    "img_1, label_1 = train_dataset[1]\n",
    "img_0 = img_0.numpy().reshape(28, 28)\n",
    "img_1 = img_1.numpy().reshape(28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 2 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"198.378068pt\" version=\"1.1\" viewBox=\"0 0 368.925 198.378068\" width=\"368.925pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <defs>\n  <style type=\"text/css\">\n*{stroke-linecap:butt;stroke-linejoin:round;}\n  </style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M -0 198.378068 \nL 368.925 198.378068 \nL 368.925 0 \nL -0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 26.925 174.499943 \nL 179.106818 174.499943 \nL 179.106818 22.318125 \nL 26.925 22.318125 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g clip-path=\"url(#p29bbca9e2e)\">\n    <image height=\"153\" id=\"imagee66ca32f1b\" transform=\"scale(1 -1)translate(0 -153)\" width=\"153\" x=\"26.925\" xlink:href=\"data:image/png;base64,\niVBORw0KGgoAAAANSUhEUgAAAJkAAACZCAYAAAA8XJi6AAAABHNCSVQICAgIfAhkiAAAA05JREFUeJzt3TFrFEEYx+Hdy+oVgRQiYiM2sbK2EQkIFgYsLfwSWvrxBINfwUYsrGIKsQgkJJi7s7HKTMAU/93N5HnK4Yp54cdLwoVJv//5/aa75O7i4vLRjfT1YLc4e/LiR/WzLcxcm/fp3vfJ77AY9QbcSiIjTmTEiYy4/lX/tvjBvxmLrfJsvRr/HmOZw7yVO9hkxImMOJERJzLiREbc0PV9cdhvVX5LacRmU87bdQ3PvBimvoFNRp7IiBMZcSIjbhgeP5r6DjTOJiNOZMSJjDiREScy4vrVz91m/2jx1+qkOLu/tT3BTcYxh3lrd7DJiBMZcSIjTmTEDR8On019BxpnkxEnMuJERpzIiBMZcU1/rcQ82GTEiYw4kREnMuKGN9/2i8MWXoLuOq9fd53Xr7klREacyIgTGXEiI84T6y2Zw7yeWGcKIiNOZMSJjDivX//T7Mxev+Y2EBlxIiNOZMSJjDhPrBNnkxEnMuJERpzIiGv6mYI5vAY9pjnM6/VrJiEy4kRGnMiIExlxnlgnziYjTmTEiYw4kRHX9NdKzINNRpzIiBMZcSIjTmTEDfuv35Wn6/EvknC0d684e/jld/3DDcxcnffginlHvINNRpzIiBMZcSIjrunXr7d2doqz1fHxBDcZxxzmrd3BJiNOZMSJjDiREdf069fr09PysDJv17Uxc23efhj39evaHWwy4kRGnMiIExlxIiNu6Dblt0qbVRv/eHSxXBZnm4uL6mdbmLk27/r8fPI72GTEiYw4kREnMuLq3zlUfhm4idZnZ///4QZmvta8I97BJiNOZMSJjDiREScy4sb9i7aRLbbL/yu0Pin/908r5jBv7Q42GXEiI05kxImMuKZ/8G/5h/yaOcxbu4NNRpzIiBMZcSIjTmTEDYcfnxeHm/pzETdOf42/Q2xh5tq8Y89Vu4NNRpzIiBMZcSIjrunXr5kHm4w4kREnMuJERpzIiGv6ifWaqx67a3nmqdlkxImMOJERJzLihq4vO9usG/6mqTJv1zU+88RsMuJERpzIiBMZcSIjbrjz6cHUd6BxNhlxIiNOZMSJjLjhz8ujqe9A42wy4kRGnMiIExlxIiNuWCyXU9+BxtlkxImMOJERJzLi/gLWLqMP8VzITwAAAABJRU5ErkJggg==\" y=\"-21.499943\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m9186b5418d\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"29.642532\" xlink:href=\"#m9186b5418d\" y=\"174.499943\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <defs>\n       <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n      </defs>\n      <g transform=\"translate(26.461282 189.098381)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"83.993182\" xlink:href=\"#m9186b5418d\" y=\"174.499943\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 10 -->\n      <defs>\n       <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n      </defs>\n      <g transform=\"translate(77.630682 189.098381)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"138.343831\" xlink:href=\"#m9186b5418d\" y=\"174.499943\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 20 -->\n      <defs>\n       <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n      </defs>\n      <g transform=\"translate(131.981331 189.098381)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_4\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"m80e791e41a\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m80e791e41a\" y=\"25.035657\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 0 -->\n      <g transform=\"translate(13.5625 28.834876)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m80e791e41a\" y=\"52.210982\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 5 -->\n      <defs>\n       <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n      </defs>\n      <g transform=\"translate(13.5625 56.010201)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m80e791e41a\" y=\"79.386307\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 10 -->\n      <g transform=\"translate(7.2 83.185526)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_7\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m80e791e41a\" y=\"106.561631\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 15 -->\n      <g transform=\"translate(7.2 110.36085)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m80e791e41a\" y=\"133.736956\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 20 -->\n      <g transform=\"translate(7.2 137.536175)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_9\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m80e791e41a\" y=\"160.912281\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 25 -->\n      <g transform=\"translate(7.2 164.7115)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 26.925 174.499943 \nL 26.925 22.318125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 179.106818 174.499943 \nL 179.106818 22.318125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 26.925 174.499943 \nL 179.106818 174.499943 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 26.925 22.318125 \nL 179.106818 22.318125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"text_10\">\n    <!-- 0 -->\n    <g transform=\"translate(99.198409 16.318125)scale(0.12 -0.12)\">\n     <use xlink:href=\"#DejaVuSans-48\"/>\n    </g>\n   </g>\n  </g>\n  <g id=\"axes_2\">\n   <g id=\"patch_7\">\n    <path d=\"M 209.543182 174.499943 \nL 361.725 174.499943 \nL 361.725 22.318125 \nL 209.543182 22.318125 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g clip-path=\"url(#p8e4b9cef12)\">\n    <image height=\"153\" id=\"imagedc2f947341\" transform=\"scale(1 -1)translate(0 -153)\" width=\"153\" x=\"209.543182\" xlink:href=\"data:image/png;base64,\niVBORw0KGgoAAAANSUhEUgAAAJkAAACZCAYAAAA8XJi6AAAABHNCSVQICAgIfAhkiAAABAVJREFUeJzt3TFuE0EUh/GZ9TgKHIACIdFwBRpKiEBIlBScAtFwvZwCCQ5AEkQHFAYce2lSZd9Ea5xvd7P+fuVqsn4v+me0lj0v+eT0Q5uu2aZ8/VJKKaUmdZamRbMN10Y226b32tp9j5pNt64cr21yt95ff4/DtVHPc+53yBr6/xak/2TIhDNkwhky4Up68bVzcZfkdR8Jb0ftvivo9fr2PJd+h6zBnUw4QyacIRPOkAlnyIQrqVl0LuZF91pKKaWm+9FLdW3eYe2yBK8Vr82L4O+iBD9fqeHy7KJy3+D1ZtBv++Pn6DW4kwlnyIQzZMIZMuFKefyo/+rowTJ4OK6trWqCrFfu20b3rbxWtLaUw+o3Hx+NXoM7mXCGTDhDJpwhE86QCZc3F0+6x0sgm7b/SR/KIg/3dzWFfqfAnUw4QyacIRPOkAlX3p8/HbuGnSzzfueF1m3lO14TNYV+963BnUw4QyacIRPOkAlnyIQb9GMlHSZ3MuEMmXCGTDhDJlx59flN56LTr69+fsb9DlmDO5lwhkw4QyacIRPOkAnniPUrjlh3xLruMEMmnCETzpAJ5/Trm2qbQb9Ov9ZBMGTCGTLhDJlwhkw4R6zfZAb9OmJdB8GQCWfIhDNkwjn9GjSFfqfAnUw4QyacIRPOkAlnyIRzxPrETaFfR6xr8gyZcIZMOEMmnNOvhXMnE86QCWfIhDNkwhky4crrl+/2u8PQMY1OybSVN8jR2s2eb6bvWr+1tQPW4E4mnCETzpAJZ8iEK9tPX8auQTPnTiacIRPOkAlnyIRz+vVNtc2gX6df6yAYMuEMmXCGTDhDJlxJwaC2tnYqPbq+6X+Eva0NoPvT/51Z+C2myiTm8B6VwXRhzzPod7v6PXoN7mTCGTLhDJlwhky4Eh4IqD75B0uhAc+Dz07o2fNs+g1QNbiTCWfIhDNkwhky4QyZcIZMOEMmnCETzpAJZ8iEM2TCGTLhDJlwhkw4QyacIROunH981rmYK1/M21bGH0Ry9F3IHSJdW7t6GHy5cFM5ORPUcP8svnHU8xz6vfetfxFUDe5kwhky4QyZcIZMuHyS307hoEx/lePxvd3Gv4EZ0hT63bMGdzLhDJlwhkw4QyacIRPOEes31TaDfh2xroNgyIQzZMIZMuHCp7e2MuE5t8GDZW0adDD5uU3reO0quBY8dKeUUt7lI45mh+9SBX3Mod92fTl6De5kwhky4QyZcIZMOEMmXFmePhjsxbbBu7WhLaPjNJAp9Dt+Be5kGoAhE86QCWfIhCvr59/HrmEnufLRR1+b7d06rbRvv+0t9LtvDe5kwhky4QyZcIZMOEMmXGmOlmPXMKgpfMwypCn0604mnCETzpAJZ8iE+weW1hhJzdX/HQAAAABJRU5ErkJggg==\" y=\"-21.499943\"/>\n   </g>\n   <g id=\"matplotlib.axis_3\">\n    <g id=\"xtick_4\">\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"212.260714\" xlink:href=\"#m9186b5418d\" y=\"174.499943\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 0 -->\n      <g transform=\"translate(209.079464 189.098381)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_11\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"266.611364\" xlink:href=\"#m9186b5418d\" y=\"174.499943\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 10 -->\n      <g transform=\"translate(260.248864 189.098381)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"320.962013\" xlink:href=\"#m9186b5418d\" y=\"174.499943\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 20 -->\n      <g transform=\"translate(314.599513 189.098381)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_4\">\n    <g id=\"ytick_7\">\n     <g id=\"line2d_13\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"209.543182\" xlink:href=\"#m80e791e41a\" y=\"25.035657\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 0 -->\n      <g transform=\"translate(196.180682 28.834876)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_8\">\n     <g id=\"line2d_14\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"209.543182\" xlink:href=\"#m80e791e41a\" y=\"52.210982\"/>\n      </g>\n     </g>\n     <g id=\"text_15\">\n      <!-- 5 -->\n      <g transform=\"translate(196.180682 56.010201)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_9\">\n     <g id=\"line2d_15\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"209.543182\" xlink:href=\"#m80e791e41a\" y=\"79.386307\"/>\n      </g>\n     </g>\n     <g id=\"text_16\">\n      <!-- 10 -->\n      <g transform=\"translate(189.818182 83.185526)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_10\">\n     <g id=\"line2d_16\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"209.543182\" xlink:href=\"#m80e791e41a\" y=\"106.561631\"/>\n      </g>\n     </g>\n     <g id=\"text_17\">\n      <!-- 15 -->\n      <g transform=\"translate(189.818182 110.36085)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_11\">\n     <g id=\"line2d_17\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"209.543182\" xlink:href=\"#m80e791e41a\" y=\"133.736956\"/>\n      </g>\n     </g>\n     <g id=\"text_18\">\n      <!-- 20 -->\n      <g transform=\"translate(189.818182 137.536175)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_12\">\n     <g id=\"line2d_18\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"209.543182\" xlink:href=\"#m80e791e41a\" y=\"160.912281\"/>\n      </g>\n     </g>\n     <g id=\"text_19\">\n      <!-- 25 -->\n      <g transform=\"translate(189.818182 164.7115)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"patch_8\">\n    <path d=\"M 209.543182 174.499943 \nL 209.543182 22.318125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_9\">\n    <path d=\"M 361.725 174.499943 \nL 361.725 22.318125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_10\">\n    <path d=\"M 209.543182 174.499943 \nL 361.725 174.499943 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_11\">\n    <path d=\"M 209.543182 22.318125 \nL 361.725 22.318125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"text_20\">\n    <!-- 1 -->\n    <g transform=\"translate(281.816591 16.318125)scale(0.12 -0.12)\">\n     <use xlink:href=\"#DejaVuSans-49\"/>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p29bbca9e2e\">\n   <rect height=\"152.181818\" width=\"152.181818\" x=\"26.925\" y=\"22.318125\"/>\n  </clipPath>\n  <clipPath id=\"p8e4b9cef12\">\n   <rect height=\"152.181818\" width=\"152.181818\" x=\"209.543182\" y=\"22.318125\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(img_0)\n",
    "plt.title(label_0)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(img_1)\n",
    "plt.title(label_1)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import *\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import torch.nn as nn \n",
    "import torch \n",
    "import torch.nn.functional as F \n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mymodel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.resnet = resnet50(pretrained=True)\n",
    "        self.resnet.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "        self.resnet.fc = nn.Linear(in_features=2048, out_features=2, bias=True)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "    def forward(self, input):\n",
    "        x = self.resnet(input)\n",
    "        x = self.softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mymodel()\n",
    "model = model.cuda()\n",
    "\n",
    "myOptim = optim.Adam(model.parameters(), lr=1e-4)\n",
    "loss = torch.nn.CrossEntropyLoss().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=32, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "5914"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0/50 auc --> 0.659426079471247\n",
      "5/50 auc --> 0.6012254125935014\n",
      "10/50 auc --> 0.5599454492684793\n",
      "15/50 auc --> 0.479309969525468\n",
      "20/50 auc --> 0.5357727800424796\n",
      "25/50 auc --> 0.5915726705452434\n",
      "30/50 auc --> 0.576977381564887\n",
      "35/50 auc --> 0.6055316717457554\n",
      "40/50 auc --> 0.6094097538291051\n",
      "45/50 auc --> 0.6216685795701904\n"
     ]
    }
   ],
   "source": [
    "for e in range(0, 50):\n",
    "    model.train()\n",
    "    for img, label in train_loader:\n",
    "        img = img.cuda()\n",
    "        label = label.cuda()\n",
    "\n",
    "        myOptim.zero_grad()\n",
    "        pred = model(img)\n",
    "        cost = loss(pred, label)\n",
    "        cost.backward()\n",
    "        myOptim.step()\n",
    "    if e % 5 == 0:\n",
    "        with torch.no_grad():\n",
    "    \n",
    "            pred_list = []\n",
    "            loss_tmp = 0\n",
    "            for img, label in valid_loader:\n",
    "                img = img.cuda()\n",
    "                label = label.cuda()\n",
    "\n",
    "                pred = model(img)\n",
    "                cost = loss(pred, label)\n",
    "                loss_tmp += cost \n",
    "                pred_list.extend(pred.cpu().numpy()[:, 1])\n",
    "            \n",
    "            score = roc_auc_score(valid_y, list(pred_list))\n",
    "            print(f\"{e}/50 auc --> {score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mymodel1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.resnet = resnet50(pretrained=False)\n",
    "        self.resnet.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "        self.resnet.fc = nn.Linear(in_features=2048, out_features=2, bias=True)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "    def forward(self, input):\n",
    "        x = self.resnet(input)\n",
    "        x = self.softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = mymodel1()\n",
    "model1 = model1.cuda()\n",
    "\n",
    "myOptim1 = optim.Adam(model1.parameters(), lr=1e-4)\n",
    "loss1 = torch.nn.CrossEntropyLoss().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0/50 auc --> 0.5916825800451182\n",
      "5/50 auc --> 0.6128563607340273\n",
      "10/50 auc --> 0.6216826789884038\n",
      "15/50 auc --> 0.5060958958325089\n",
      "20/50 auc --> 0.5906212484004169\n",
      "25/50 auc --> 0.579593112228071\n",
      "30/50 auc --> 0.5969805807311248\n",
      "35/50 auc --> 0.3806904757193177\n",
      "40/50 auc --> 0.41173912613290065\n",
      "45/50 auc --> 0.37890916676560993\n"
     ]
    }
   ],
   "source": [
    "for e in range(0, 50):\n",
    "    model1.train()\n",
    "    for img, label in train_loader:\n",
    "        img = img.cuda()\n",
    "        label = label.cuda()\n",
    "\n",
    "        myOptim1.zero_grad()\n",
    "        pred = model1(img)\n",
    "        cost = loss1(pred, label)\n",
    "        cost.backward()\n",
    "        myOptim1.step()\n",
    "    if e % 5 == 0:\n",
    "        with torch.no_grad():\n",
    "            model1.eval()\n",
    "\n",
    "            pred_list = []\n",
    "            loss_tmp = 0\n",
    "            for img, label in valid_loader:\n",
    "                img = img.cuda()\n",
    "                label = label.cuda()\n",
    "\n",
    "                pred = model1(img)\n",
    "                cost = loss1(pred, label)\n",
    "                loss_tmp += cost \n",
    "                pred_list.extend(pred.cpu().numpy()[:, 1])\n",
    "            \n",
    "            score = roc_auc_score(valid_y, list(pred_list))\n",
    "            print(f\"{e}/50 auc --> {score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mymodel2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.resnet = resnet18(pretrained=False)\n",
    "        self.resnet.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "        self.resnet.fc = nn.Linear(in_features=512, out_features=2, bias=True)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "    def forward(self, input):\n",
    "        x = self.resnet(input)\n",
    "        x = self.softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = mymodel2()\n",
    "model2 = model2.cuda()\n",
    "\n",
    "myOptim2 = optim.Adam(model2.parameters(), lr=1e-4)\n",
    "loss2 = torch.nn.CrossEntropyLoss().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0/50 auc --> 0.6664132894025145\n",
      "5/50 auc --> 0.6557975818260973\n",
      "10/50 auc --> 0.677651432698777\n",
      "15/50 auc --> 0.6766833551008562\n",
      "20/50 auc --> 0.6683626370364506\n",
      "25/50 auc --> 0.6668554834368939\n",
      "30/50 auc --> 0.6032368471392199\n",
      "35/50 auc --> 0.6839847924169866\n",
      "40/50 auc --> 0.4877644259310563\n",
      "45/50 auc --> 0.551698608857403\n"
     ]
    }
   ],
   "source": [
    "for e in range(0, 50):\n",
    "    model2.train()\n",
    "    train_label_list = []\n",
    "    train_pred_list\n",
    "    for img, label in train_loader:\n",
    "        img = img.cuda()\n",
    "        label = label.cuda()\n",
    "\n",
    "        myOptim2.zero_grad()\n",
    "        pred = model2(img)\n",
    "        cost = loss2(pred, label)\n",
    "        cost.backward()\n",
    "        myOptim2.step()\n",
    "        train_pred_list.extend(pred.cpu().numpy()[:, 1])\n",
    "        train_label_list.extend(label.cpu().numpy())\n",
    "    if e % 5 == 0:\n",
    "        with torch.no_grad():\n",
    "            model2.eval()\n",
    "\n",
    "            pred_list = []\n",
    "            loss_tmp = 0\n",
    "            for img, label in valid_loader:\n",
    "                img = img.cuda()\n",
    "                label = label.cuda()\n",
    "\n",
    "                pred = model2(img)\n",
    "                cost = loss2(pred, label)\n",
    "                loss_tmp += cost \n",
    "                pred_list.extend(pred.cpu().numpy()[:, 1])\n",
    "            \n",
    "            score = roc_auc_score(valid_y, list(pred_list))\n",
    "            train_score = roc_auc_score(list(train_label_list), list(train_pred_list))\n",
    "            print(f\"{e}/50 auc --> {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mymodel3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.resnet = resnet18(pretrained=True)\n",
    "        self.resnet.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "        self.resnet.fc = nn.Linear(in_features=512, out_features=2, bias=True)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "    def forward(self, input):\n",
    "        x = self.resnet(input)\n",
    "        x = self.softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-5c106cde.pth\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=46827520.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "70c9af60bd724a7bb29ba654a9c2890d"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model3 = mymodel3()\n",
    "model3 = model3.cuda()\n",
    "\n",
    "myOptim3 = optim.Adam(model3.parameters(), lr=1e-4)\n",
    "loss3 = torch.nn.CrossEntropyLoss().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in range(0, 50):\n",
    "    model3.train()\n",
    "    for img, label in train_loader:\n",
    "        img = img.cuda()\n",
    "        label = label.cuda()\n",
    "\n",
    "        myOptim3.zero_grad()\n",
    "        pred = model3(img)\n",
    "        cost = loss3(pred, label)\n",
    "        cost.backward()\n",
    "        myOptim3.step()\n",
    "    if e % 5 == 0:\n",
    "        with torch.no_grad():\n",
    "            model3.eval()\n",
    "\n",
    "            pred_list = []\n",
    "            loss_tmp = 0\n",
    "            for img, label in valid_loader:\n",
    "                img = img.cuda()\n",
    "                label = label.cuda()\n",
    "\n",
    "                pred = model3(img)\n",
    "                cost = loss3(pred, label)\n",
    "                loss_tmp += cost \n",
    "                pred_list.extend(pred.cpu().numpy()[:, 1])\n",
    "            \n",
    "            score = roc_auc_score(valid_y, list(pred_list))\n",
    "            print(f\"{e}/50 auc --> {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting efficientnet_pytorch\n",
      "  Downloading https://files.pythonhosted.org/packages/2e/a0/dd40b50aebf0028054b6b35062948da01123d7be38d08b6b1e5435df6363/efficientnet_pytorch-0.7.1.tar.gz\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from efficientnet_pytorch) (1.8.1+cu101)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch->efficientnet_pytorch) (1.19.5)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->efficientnet_pytorch) (3.7.4.3)\n",
      "Building wheels for collected packages: efficientnet-pytorch\n",
      "  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.1-cp37-none-any.whl size=16443 sha256=73a74990eeba4182738d1f7d924aeaa1e2a4f344a6e2362d4c8ad7f4fa8a3d10\n",
      "  Stored in directory: /root/.cache/pip/wheels/84/27/aa/c46d23c4e8cc72d41283862b1437e0b3ad318417e8ed7d5921\n",
      "Successfully built efficientnet-pytorch\n",
      "Installing collected packages: efficientnet-pytorch\n",
      "Successfully installed efficientnet-pytorch-0.7.1\n"
     ]
    }
   ],
   "source": [
    "!pip install efficientnet_pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from efficientnet_pytorch import EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}